{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPMSBrDTA2O53oOmJi/srD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmahmoodiagents/NLP/blob/main/Semantic_Analysis_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_md --q\n",
        "# !pip install gensim --q"
      ],
      "metadata": {
        "id": "ySiwQhKvvIF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
      ],
      "metadata": {
        "id": "IXBiKG2IvFK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    [\"I\", \"love\", \"natural\", \"language\", \"processing\"],\n",
        "    [\"You\", \"can\", \"use\", \"Word2Vec\", \"for\", \"word\", \"embeddings\"],\n",
        "    [\"Machine\", \"learning\", \"is\", \"fun\"],\n",
        "    [\"Deep\", \"learning\", \"is\", \"a\", \"subset\", \"of\", \"machine\", \"learning\"]\n",
        "]\n",
        "sentences = [[w.lower() for w in s] for s in sentences]\n",
        "labels = [1, 0, 1, 0]"
      ],
      "metadata": {
        "id": "tM3db6RLvYKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_words = sorted(set(word for sent in sentences for word in sent))\n",
        "old_vocab = {word: idx for idx, word in enumerate(vocab_words)}\n",
        "vocab = {word: idx + 1 for word, idx in old_vocab.items()}    # shift\n",
        "\n",
        "print(\"Vocab:\", vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou-j3bkfvs9Y",
        "outputId": "9a1ac860-7b58-4017-ec28-d3df2110f1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab: {'a': 1, 'can': 2, 'deep': 3, 'embeddings': 4, 'for': 5, 'fun': 6, 'i': 7, 'is': 8, 'language': 9, 'learning': 10, 'love': 11, 'machine': 12, 'natural': 13, 'of': 14, 'processing': 15, 'subset': 16, 'use': 17, 'word': 18, 'word2vec': 19, 'you': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")   # 300-dim embeddings\n",
        "embed_dim = nlp.vocab.vectors_length\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "KGJfTxMFvxMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size + 1, embed_dim))\n",
        "\n",
        "for word, idx in vocab.items():\n",
        "    if word in nlp.vocab:\n",
        "        embedding_matrix[idx] = nlp.vocab[word].vector\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.randn(embed_dim) * 0.1\n",
        "\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "mCEglKxDv1YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_sentences = [[vocab[w] for w in sent] for sent in sentences]"
      ],
      "metadata": {
        "id": "mrowz14lv68o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = torch.tensor(self.sequences[idx], dtype=torch.long)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return seq, label"
      ],
      "metadata": {
        "id": "bhozvyX7v--q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    sequences, labels = zip(*batch)\n",
        "    lengths = torch.tensor([len(s) for s in sequences])\n",
        "    padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    return padded, lengths, labels"
      ],
      "metadata": {
        "id": "iqad_9NKwByy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(indexed_sentences, labels)\n",
        "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "xx43a3IxwD7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, emb_matrix, hidden_dim=128, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        vocab_size, embed_dim = emb_matrix.shape\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embed_dim,\n",
        "            padding_idx=0          # <- padding ignored\n",
        "        )\n",
        "\n",
        "        self.embedding.weight.data.copy_(emb_matrix)\n",
        "        self.embedding.weight.requires_grad = False  # freeze word2vec\n",
        "\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, padded, lengths):\n",
        "        embed = self.embedding(padded)\n",
        "        packed = pack_padded_sequence(embed, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        out, (h, c) = self.lstm(packed)\n",
        "        logits = self.fc(h[-1])  # final hidden state\n",
        "        return logits"
      ],
      "metadata": {
        "id": "d_YY5jCnwHjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMClassifier(embedding_matrix)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "fGD2bOPhwMsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    for padded, lengths, labels in loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(padded, lengths)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGT2GMUXwQRM",
        "outputId": "82f2f5d6-463a-4a8c-bba6-6ff7ceb15408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 0.7059\n",
            "Epoch 2 Loss: 0.6578\n",
            "Epoch 3 Loss: 0.6368\n",
            "Epoch 4 Loss: 0.6255\n",
            "Epoch 5 Loss: 0.5799\n",
            "Epoch 6 Loss: 0.5457\n",
            "Epoch 7 Loss: 0.4439\n",
            "Epoch 8 Loss: 0.3821\n",
            "Epoch 9 Loss: 0.3903\n",
            "Epoch 10 Loss: 0.2496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSDM_uV3u0e0"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_sentence = [\"machine\", \"learning\", \"is\", \"cool\"]\n",
        "test_ids = torch.tensor([vocab.get(w, 0) for w in test_sentence]).unsqueeze(0)\n",
        "test_len = torch.tensor([len(test_sentence)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(test_ids, test_len)\n",
        "    pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "print(\"\\nPredicted class:\", pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrZ2_eghwafz",
        "outputId": "75c25edf-448b-49e7-b062-6af0d1d7f4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zSD0zPswbCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}